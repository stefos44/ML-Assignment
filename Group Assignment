import pandas as pd
import logging
import json
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from collections import Counter



def main():
    logging.getLogger().setLevel(logging.INFO)

    logging.info("Loading training/test data")
    train = pd.DataFrame.from_records(json.load(open('train.json'))).fillna("")
    test = pd.DataFrame.from_records(json.load(open('test.json'))).fillna("")


    logging.info("Splitting validation")
    train, val = train_test_split(train, stratify=train['year'], random_state=123)


    ######PREPROCESSING########

    #dropping the editor column because of missing values
    train = train.drop('editor', axis=1)
    test = test.drop('editor', axis=1)

    # Converting the 'author' column from list to a string seperated by commas
    train['author'] = train['author'].apply(lambda x: ', '.join(x))
    val['author'] = val['author'].apply(lambda x: ', '.join(x))
    test['author'] = test['author'].apply(lambda x: ', '.join(x))
    
    ###### One-hot encoding for ENTRYTYPE regarding proceedings, inproceedings ######

    train = train.join(pd.get_dummies(train.ENTRYTYPE)).drop(['ENTRYTYPE'], axis=1)
    test = test.join(pd.get_dummies(test.ENTRYTYPE)).drop(['ENTRYTYPE'], axis=1)
    val = val.join(pd.get_dummies(val.ENTRYTYPE)).drop(['ENTRYTYPE'], axis=1)

    ######## FEATURE ENGINEERING ########


    # HAS_ABSTRACT FEATURE
    train['has_abstract'] = train['abstract'].apply(lambda x: 1 if len(x.strip()) > 0 else 0)  # Here we create a binary feauture in order to see if an abstract exists
    val['has_abstract'] = val['abstract'].apply(lambda x: 1 if len(x.strip()) > 0 else 0)      # if the column of Abstract has no whitespaces characters it has an abstract
    test['has_abstract'] = test['abstract'].apply(lambda x: 1 if len(x.strip()) > 0 else 0)    # So 1 = Has abstract,    0 = Column is empty / no abstract

    # HAS_PUBLISHER FEATURE
    train['has_publisher'] = train['publisher'].apply(lambda x: 1 if len(x.strip()) > 0 else 0)  #Same logic as above here
    val['has_publisher'] = val['publisher'].apply(lambda x: 1 if len(x.strip()) > 0 else 0)
    test['has_publisher'] = test['publisher'].apply(lambda x: 1 if len(x.strip()) > 0 else 0)



    # Define the ColumnTransformer
    featurizer = ColumnTransformer(
        transformers=[
            ("title", CountVectorizer(), "title"),
            ("abstract", CountVectorizer(max_features=150), "abstract"),     # with CountVectorizer it transforms the text in the title in numerical values for better processing
            ('publisher', CountVectorizer(), 'publisher'),
            ('author', CountVectorizer(), 'author'),             # passthrough doesnt change the columns through transformation but keeps them the same
            ("proceedings", 'passthrough', ['proceedings']),
            ("inproceedings", 'passthrough', ['inproceedings']),
            ("has_abstract", 'passthrough', ['has_abstract']),
            ("has_publisher", 'passthrough', ['has_publisher'])
        ],
        remainder='drop'                                                 #anything that wasnt mentioned before should be dropped
    )


    # Logistic Regression model
    logistic = make_pipeline(featurizer, LogisticRegression(max_iter=10000))

    logging.info("Fitting Logistic Regression model")
    logistic.fit(train.drop('year', axis=1), train['year'].values)

    logging.info("Evaluating Logistic Regression on validation data")
    err_logistic = mean_absolute_error(val['year'].values, logistic.predict(val.drop('year', axis=1)))
    logging.info(f"Logistic Regression MAE: {err_logistic}")

    # RandomForestRegressor model
    random_forest = make_pipeline(featurizer, RandomForestRegressor(n_estimators = 200, random_state=123, n_jobs = -1))    #basic model parameters because hyperparameters were computanionally expensive

    logging.info("Fitting RandomForestRegressor model")
    random_forest.fit(train.drop('year', axis=1), train['year'].values)

    logging.info("Evaluating RandomForestRegressor on validation data")
    err_rf = mean_absolute_error(val['year'].values, random_forest.predict(val.drop('year', axis=1)))
    logging.info(f"Random Forest Regressor MAE: {err_rf}")
    logging.info(f"Predicting on test")
    pred = random_forest.predict(test)
    test['year'] = pred
    logging.info("Writing prediction file")
    test.to_json("predicted_rf_stef.json", orient='records', indent=2)






    #### Creating a plot to illustrate which were the 5 most important features ###

    # Fetching the importances of the feautures while also getting the transformed columns
    rf_model = random_forest.named_steps['randomforestregressor']
    feature_importances = rf_model.feature_importances_
    column_names = random_forest.named_steps['columntransformer'].get_feature_names_out()
    feature_importance_df = pd.DataFrame({'Feature': column_names, 'Importance': feature_importances}) #create a df and afterwards sort which ones are important
    feature_importance_df = feature_importance_df.sort_values('Importance', ascending=False)
    top_n = 5
    plt.figure(figsize=(8, 4))
    plt.barh(feature_importance_df['Feature'][:top_n], feature_importance_df['Importance'][:top_n])
    plt.xlabel('Importance')
    plt.title(f'Top {top_n} Important Features')
    plt.gca().invert_yaxis()
    plt.show()

if __name__ == "__main__":
        main()
    


import pandas as pd
import logging
import json
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import RandomForestRegressor  # Import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
# import further scikit-learn functions
from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler, MaxAbsScaler,PowerTransformer
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score
from sklearn.feature_selection import RFECV
from sklearn.linear_model import SGDClassifier, LogisticRegression
from sklearn.compose import ColumnTransformer
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score, roc_curve
from sklearn.dummy import DummyClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier

def main():
    logging.getLogger().setLevel(logging.INFO)
    logging.info("Loading training/test data")
    
    # Load data from JSON files
    train = pd.DataFrame.from_records(json.load(open('train.json'))).fillna("")
    test = pd.DataFrame.from_records(json.load(open('test.json'))).fillna("")

    # Split training data into training and validation sets
    train, val = train_test_split(train, stratify=train['year'], test_size=0.2, random_state=123)

    # Define featurizer using CountVectorizer
    featurizer = ColumnTransformer(
        transformers=[("title", CountVectorizer(), "title")],
        remainder='drop'
    )

    # Create a pipeline with RandomForestRegressor
    random_forest = make_pipeline(featurizer, RandomForestRegressor(n_estimators=100, random_state=123, n_jobs = 3))

    logging.info("Fitting models")
    
    # Fit the Random Forest model on the training data
    random_forest.fit(train.drop('year', axis=1), train['year'].values)

    logging.info("Evaluating on validation data")
    
    # Evaluate the Random Forest model on the validation set
    err_rf = mean_absolute_error(val['year'].values, random_forest.predict(val.drop('year', axis=1)))
    logging.info(f"Random Forest regressor MAE: {err_rf}")

    logging.info("Predicting on test")
    
    # Predict on the test set using the Random Forest regressor
    pred = random_forest.predict(test)

    # Assign predicted values to the 'year' column in the test DataFrame
    test['year'] = pred

    logging.info("Writing prediction file")
    
    # Write the predicted DataFrame to a JSON file
    test.to_json("predicted_rf.json", orient='records', indent=2)

if __name__ == "__main__":
    main()
